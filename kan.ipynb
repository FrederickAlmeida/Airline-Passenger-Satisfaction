{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from kan import KAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando e dividindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_processed.csv')\n",
    "df_test = pd.read_csv('data/test_processed.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['satisfaction_satisfied']).values\n",
    "y_train = df_train['satisfaction_satisfied'].values\n",
    "X_test = df_test.drop(columns=['satisfaction_satisfied']).values\n",
    "y_test = df_test['satisfaction_satisfied'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo para tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_label = torch.tensor(y_train, dtype=torch.long)\n",
    "test_input = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_label = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "dataset = {\n",
    "    'train_input': train_input,\n",
    "    'train_label': train_label,\n",
    "    'test_input': test_input,\n",
    "    'test_label': test_label\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(width, grid, k, steps, loss_fn, opt):\n",
    "    model = KAN(width=width, grid=grid, k=k)\n",
    "\n",
    "    # Funções de avaliação\n",
    "    def train_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "    def test_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).float())\n",
    "    \n",
    "    results = model.fit(dataset, opt=opt, steps=steps, metrics=(train_acc, test_acc), loss_fn=loss_fn)\n",
    "\n",
    "    for key in results:\n",
    "        results[key] = np.array(results[key])\n",
    "\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evolution(train_accuracy, test_accuracy, train_loss, test_loss):\n",
    "    # Plot for first and second arrays\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_accuracy, 'g', label='Train')  # Green color\n",
    "    plt.plot(test_accuracy, 'r', label='Test')  # Red color\n",
    "    plt.scatter(len(train_accuracy) - 1, train_accuracy[-1], color='g')  # Point for the last element of train_accuracy\n",
    "    plt.text(len(train_accuracy) - 1, train_accuracy[-1], f'{train_accuracy[-1]*100:.2f}', fontsize=12, ha='right')\n",
    "    plt.scatter(len(test_accuracy) - 1, test_accuracy[-1], color='r')  # Point for the last element of test_accuracy\n",
    "    plt.text(len(test_accuracy) - 1, test_accuracy[-1], f'{test_accuracy[-1]*100:.2f}', fontsize=12, ha='right')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot for third and fourth arrays\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, 'g', label='Train')  # Green color\n",
    "    plt.plot(test_loss, 'r', label='Test')  # Red color\n",
    "    plt.scatter(len(train_loss) - 1, train_loss[-1], color='g')  # Point for the last element of train_loss\n",
    "    plt.text(len(train_loss) - 1, train_loss[-1], f'{train_loss[-1]:.4f}', fontsize=12, ha='right')\n",
    "    plt.scatter(len(test_loss) - 1, test_loss[-1], color='r')  # Point for the last element of test_loss\n",
    "    plt.text(len(test_loss) - 1, test_loss[-1], f'{test_loss[-1]:.4f}', fontsize=12, ha='right')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(param_grid):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_results = None\n",
    "\n",
    "    # Iterar sobre todas as combinações de hiperparâmetros\n",
    "    for width in param_grid['width']:\n",
    "        for grid in param_grid['grid']:\n",
    "            for k in param_grid['k']:\n",
    "                for steps in param_grid['steps']:\n",
    "                    for opt in param_grid['opt']:\n",
    "                        results, model = train_and_evaluate_model([X_train.shape[1], 2], 3, 3, 10, loss_fn, opt)\n",
    "                        train_acc = results['train_acc'][-1]\n",
    "                        test_acc = results['test_acc'][-1]\n",
    "                        print(f\"Width: {width}, Grid: {grid}, K: {k}, Steps: {steps}, Optimizer: {opt} Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "                        \n",
    "                        if test_acc > best_accuracy:\n",
    "                            best_accuracy = test_acc\n",
    "                            best_results = results\n",
    "                            best_params = {'width': width, 'grid': grid, 'k': k, 'steps': steps, 'opt': opt}\n",
    "                            best_model = model\n",
    "    \n",
    "    return best_params, best_results, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "param_grid = {\n",
    "    'width': [[X_train.shape[1], 2]],\n",
    "    'grid': [2],\n",
    "    'k': [2],\n",
    "    'steps': [10, 20, 30, 40],\n",
    "    'opt': ['Adam', 'SGD', 'LBFGS']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.49e+00 | test loss: 1.95e+00 | reg: 4.12e+01 :  60%|█▊ | 6/10 [00:11<00:07,  1.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_params, results, model \u001b[38;5;241m=\u001b[39m grid_search(param_grid)\n\u001b[1;32m      2\u001b[0m plot_evolution(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[53], line 13\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m steps \u001b[38;5;129;01min\u001b[39;00m param_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m opt \u001b[38;5;129;01min\u001b[39;00m param_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 13\u001b[0m         results, model \u001b[38;5;241m=\u001b[39m train_and_evaluate_model([X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m, loss_fn, opt)\n\u001b[1;32m     14\u001b[0m         train_acc \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m         test_acc \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[51], line 11\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(width, grid, k, steps, loss_fn, opt)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_acc\u001b[39m():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean((torch\u001b[38;5;241m.\u001b[39margmax(model(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(dataset, opt\u001b[38;5;241m=\u001b[39mopt, steps\u001b[38;5;241m=\u001b[39msteps, metrics\u001b[38;5;241m=\u001b[39m(train_acc, test_acc), loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     14\u001b[0m     results[key] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results[key])\n",
      "File \u001b[0;32m~/miniconda3/envs/redesneurais/lib/python3.12/site-packages/kan/MultKAN.py:828\u001b[0m, in \u001b[0;36mMultKAN.fit\u001b[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device, singularity_avoiding, y_th, reg_metric)\u001b[0m\n\u001b[1;32m    825\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    826\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 828\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m loss_fn_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m][test_id]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)), dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m][test_id]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;241m%\u001b[39m log \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss: \u001b[39m\u001b[38;5;132;01m%.2e\u001b[39;00m\u001b[38;5;124m | test loss: \u001b[39m\u001b[38;5;132;01m%.2e\u001b[39;00m\u001b[38;5;124m | reg: \u001b[39m\u001b[38;5;132;01m%.2e\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (torch\u001b[38;5;241m.\u001b[39msqrt(train_loss)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), torch\u001b[38;5;241m.\u001b[39msqrt(test_loss)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), reg_\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/miniconda3/envs/redesneurais/lib/python3.12/site-packages/kan/MultKAN.py:342\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[0;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# self.neurons_scale.append(torch.mean(torch.abs(x), dim=0))\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m#grid_reshape = self.act_fun[l].grid.reshape(self.width_out[l + 1], self.width_in[l], -1)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m input_range \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(preacts, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m--> 342\u001b[0m output_range_spline \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(postacts_numerical, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# for training, only penalize the spline part\u001b[39;00m\n\u001b[1;32m    343\u001b[0m output_range \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(postacts, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# for visualization, include the contribution from both spline + symbolic\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# save edge_scale\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params, results, model = grid_search(param_grid)\n",
    "plot_evolution(results['train_acc'], results['test_acc'], results['train_loss'], results['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redesneurais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
